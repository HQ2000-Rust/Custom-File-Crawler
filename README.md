# Custom-File-Crawler - a fast, concurrent, customisable and fully documented file crawler!
Features:
- fully multithreaded by default (2x - x speedup)
- Two options:
  - async
  - non-async
- set maximum traversal depth
- set file / folder regex
- lazyness (see lazy evaluation)
- execution a closure for every file (in the defined scope)
- having persistent data across closure invocations
- (set start directory)

## Examples
I've made some examples, they're a [here]() and will be added to the repo soon too
